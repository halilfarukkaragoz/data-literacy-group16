{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper ipynb while you write ff_ functions\n",
    "\n",
    "bu notebook ile ipynb enviroment'inden yararlanabileceksiniz. isiniz daha rahat olur umarim.\n",
    "\n",
    "Bu ipynb'daki `YourFeatureFunctions` class'ina `ff_` yazdiktan sonra onlari `feature_funcs.py` dosyasina kopyalamayi unutmayin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "pwd  = Path(os.getcwd())\n",
    "sys.path.append(str(pwd.parent.parent)) # needed to use \"koray\" module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;2m✔ Successfully loaded dataframes\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from koray.datastore.util import get_dataframes_concatd\n",
    "from koray.feature_calculation.util import get_features\n",
    "\n",
    "conference_invitations = [\n",
    "# 'NeurIPS.cc/2022/Conference/-/Blind_Submission',\n",
    "'ICLR.cc/2023/Conference/-/Blind_Submission',\n",
    "# 'ICLR.cc/2022/Conference/-/Blind_Submission',\n",
    "# 'ICLR.cc/2021/Conference/-/Blind_Submission',\n",
    "]\n",
    "\n",
    "master_paper_df, master_review_df, master_other_replies_df = get_dataframes_concatd(conference_invitations)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ff_example_feature_calculator_function(\n",
    "    paper_df: 'pd.DataFrame',  # i'th paper's data\n",
    "    review_df: 'pd.DataFrame',  # i'th paper's reviews\n",
    "    other_replies_df: 'pd.DataFrame',  # i'th paper's nonreviews\n",
    "    master_paper_df: 'pd.DataFrame',  # all papers' data in the conference\n",
    "    master_review_df: 'pd.DataFrame',  # all papers' reviews in the conference\n",
    "    master_other_replies_df: 'pd.DataFrame',  # all papers' nonreviews in the conference\n",
    "):\n",
    "    # Note: in the current implementation master_ dataframmes are for 1 conference.\n",
    "    # However, this behavior depends on how FeatureExtractor is used.\n",
    "\n",
    "    # these overwrite the dtype of the feature_df column\n",
    "    __overwrite_dtype__ = np.float64\n",
    "    __overwrite_dtype__ = np.int64\n",
    "\n",
    "    # write your feature calculation here\n",
    "    ...\n",
    "\n",
    "    return 1234  # this will be the value in the feature_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function koray.feature_calculation.feature_funcs._extract_numeric_prefix(maybe_string: object) -> int>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# note there are some util functions\n",
    "\n",
    "from koray.feature_calculation.feature_funcs import _extract_numeric_prefix\n",
    "\n",
    "_extract_numeric_prefix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# don't forget to add the new feature functions to feature_funcs.py\n",
    "\n",
    "class YourFeatureFunctions:\n",
    "    @staticmethod\n",
    "    def ff_review_count(paper_df: 'pd.DataFrame', review_df: 'pd.DataFrame', **kwargs):\n",
    "        __overwrite_dtype__ = np.float64\n",
    "        return len(review_df)\n",
    "\n",
    "    # @staticmethod\n",
    "    # def ff_reviewer_content(paper_df: 'pd.DataFrame', review_df: 'pd.DataFrame', other_replies_df: 'pd.DataFrame', **kwargs):\n",
    "    #     # say this your new feature function. you can experiment with dataframes this way.\n",
    "\n",
    "    #     print(\"\\n\\npaper_df\")\n",
    "    #     display(paper_df)\n",
    "    #     print(\"\\n\\nreview_df\")\n",
    "    #     display(review_df)\n",
    "    #     print(\"\\n\\nother_replies_df\")\n",
    "    #     display(other_replies_df)\n",
    "\n",
    "    #     print(\"=====================================\")\n",
    "\n",
    "    #     content_dicts = review_df['content']\n",
    "    #     print(\"\\n\\ncontent_dicts\")\n",
    "    #     display(content_dicts)\n",
    "    #     print(type(content_dicts))\n",
    "\n",
    "    #     print(\"\\n\\n\")\n",
    "    #     one_review_content = content_dicts.iloc[0]\n",
    "    #     print(\"one_review_content = \", one_review_content)\n",
    "    #     print(\"one_review_content length = \", len(one_review_content))\n",
    "    #     print(\"one_review_content type = \", type(one_review_content))\n",
    "    #     print(\"one_review_content keys = \", one_review_content.keys())\n",
    "    #     print(\"one_review_content['correctness'] = \", one_review_content['correctness'])\n",
    "\n",
    "    #     assert False\n",
    "\n",
    "    #     return 0\n",
    "\n",
    "    @staticmethod\n",
    "    def ff_yusuf_idk(review_df: 'pd.DataFrame', **kwargs):    \n",
    "        return 213\n",
    "        display(review_df['content'])\n",
    "\n",
    "        print(\"\\n\\n\")\n",
    "        display(review_df['content'].iloc[0])\n",
    "\n",
    "        display(review_df['content'].apply(lambda x: _extract_numeric_prefix(x.get('correctness'))))\n",
    "\n",
    "\n",
    "\n",
    "        assert False, \"this for testing purposes\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3796 [00:00<?, ?it/s]"
     ]
    },
    {
     "data": {
      "text/plain": [
       "14380    {'confidence': '4: You are confident in your a...\n",
       "14381    {'confidence': '4: You are confident in your a...\n",
       "14382    {'confidence': '4: You are confident in your a...\n",
       "Name: content, dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'confidence': '4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.',\n",
       " 'summary_of_the_paper': 'The paper proposes an augmentation technique for video action recognition named GM (ghost motion). In specific, GM generates the fused clips via the shifted channel and temporal misalignment, encouraging the model to alleviate over-fitting. Besides, the authors apply logits smoothing on the temporal-sensitive benchmark (SSv1/v2) for emphasizing temporal dependency. The experiments demonstrate that GM improves frame-wise accuracy and boosts multiple baseline architectures significantly.',\n",
       " 'strength_and_weaknesses': \"Strength:\\n+ The way of combining channel disorder and temporal misalignment is novel and interesting. This approach enlarges the input space and transfers the semantic frames to adjacent frames. \\n+ The method is computationally friendly and introduces minimal overhead.\\n+ The experimental results are comprehensive on various benchmarks including SSv1, SSv2, UCF, HMDB, ActivityNet and Mini-Kinetics.\\n+ The paper is generally easy to follow.\\n\\nWeakness:\\n- Miss the ablation study on the disorder channel, which is one of the key components in the paper. Namely, what the performance will be if the mixing video is TSM-like, $(C^R_{i}, C^G_{i}, C^B_{i+1})\\\\times H \\\\times W$ or $(C^R_{i-1}, C^G_{i}, C^B_{i})\\\\times H \\\\times W$. \\n- All the baseline performance is far lower than SOTA. I understand for a fair comparison, the paper unifies the training and test recipes and reproduces the 'bad' results of many previous methods. But the community would be more interested in how much the augmentation technique pushes prior arts and the absolute improvement on top of the baseline methods. \\n- The logits smoothing is orthogonal to the ghost motion augmentation and more looks like add-on to improve the performance on Something-Something dataset. What is the result only equipped with ghost motion augmentation? Is it still effective?\",\n",
       " 'clarity,_quality,_novelty_and_reproducibility': 'Clarity: The citing format is not precise. Many citations in the paper are supposed to be ~\\\\citep{} instead of ~\\\\cite{}. For example, in the first paragraph of the introduction: TSM Lin et al. (2019) ---> TSM (Lin et al. 2019). Abundant wrong citation formats distract the clarity of the paper. \\n\\nReproducibility: The implementation details are specific and easy to follow for the practitioners. \\n\\nOriginality: The method is novel and original, though the shifting trick is introduced in the video action recognition field before [1].\\n\\n[1] TSM: Temporal Shift Module for Efficient Video Understanding. ICCV 2019',\n",
       " 'summary_of_the_review': 'Overall, it is a good paper. The paper introduces a simple yet effective augmentation method to resist over-fitting for video action recognition. The experiments verify the augmentation boosts the performance considerably across the board. Thus, my initial rating is borderline accept. I would like to see the responses from the authors during the discussion period.',\n",
       " 'correctness': '3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.',\n",
       " 'technical_novelty_and_significance': '3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.',\n",
       " 'empirical_novelty_and_significance': '3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.',\n",
       " 'flag_for_ethics_review': ['NO.'],\n",
       " 'recommendation': '6: marginally above the acceptance threshold'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "14380    3\n",
       "14381    3\n",
       "14382    2\n",
       "Name: content, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/3796 [00:00<04:07, 15.35it/s]\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "this for testing purposes",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mkoray\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfeature_calculation\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpaper_features\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m FeatureExtractor\n\u001b[1;32m      3\u001b[0m fe \u001b[38;5;241m=\u001b[39m FeatureExtractor(master_paper_df, master_review_df, master_other_replies_df, YourFeatureFunctions)\n\u001b[0;32m----> 4\u001b[0m \u001b[43mfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextract_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m fe\u001b[38;5;241m.\u001b[39mfeature_df\n",
      "File \u001b[0;32m~/data-literacy-group16/koray/feature_calculation/paper_features.py:112\u001b[0m, in \u001b[0;36mFeatureExtractor.extract_features\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mextract_features\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    107\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"main function to extract features\"\"\"\u001b[39;00m\n\u001b[1;32m    109\u001b[0m     feature_df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    110\u001b[0m \u001b[43m        \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreview_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mother_replies_df\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    111\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[0;32m--> 112\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroupby\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mreplyto\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprogress_apply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    113\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_extract_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    114\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mreset_index()\n\u001b[1;32m    116\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeature_df \u001b[38;5;241m=\u001b[39m feature_df\u001b[38;5;241m.\u001b[39mrename(columns\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreplyto\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpaper_id\u001b[39m\u001b[38;5;124m'\u001b[39m})\n\u001b[1;32m    118\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moverwrite_dtypes()\n",
      "File \u001b[0;32m~/data-literacy-group16/koray/.venv/lib/python3.13/site-packages/tqdm/std.py:917\u001b[0m, in \u001b[0;36mtqdm.pandas.<locals>.inner_generator.<locals>.inner\u001b[0;34m(df, func, *args, **kwargs)\u001b[0m\n\u001b[1;32m    914\u001b[0m \u001b[38;5;66;03m# Apply the provided function (in **kwargs)\u001b[39;00m\n\u001b[1;32m    915\u001b[0m \u001b[38;5;66;03m# on the df using our wrapper (which provides bar updating)\u001b[39;00m\n\u001b[1;32m    916\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 917\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf_function\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwrapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    918\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    919\u001b[0m     t\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m~/data-literacy-group16/koray/.venv/lib/python3.13/site-packages/pandas/core/groupby/groupby.py:1824\u001b[0m, in \u001b[0;36mGroupBy.apply\u001b[0;34m(self, func, include_groups, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1822\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m option_context(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmode.chained_assignment\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m   1823\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1824\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_python_apply_general\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_selected_obj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1825\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   1826\u001b[0m             \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj, Series)\n\u001b[1;32m   1827\u001b[0m             \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_selection \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1828\u001b[0m             \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_selected_obj\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_obj_with_exclusions\u001b[38;5;241m.\u001b[39mshape\n\u001b[1;32m   1829\u001b[0m         ):\n\u001b[1;32m   1830\u001b[0m             warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m   1831\u001b[0m                 message\u001b[38;5;241m=\u001b[39m_apply_groupings_depr\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   1832\u001b[0m                     \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapply\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1835\u001b[0m                 stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[1;32m   1836\u001b[0m             )\n",
      "File \u001b[0;32m~/data-literacy-group16/koray/.venv/lib/python3.13/site-packages/pandas/core/groupby/groupby.py:1885\u001b[0m, in \u001b[0;36mGroupBy._python_apply_general\u001b[0;34m(self, f, data, not_indexed_same, is_transform, is_agg)\u001b[0m\n\u001b[1;32m   1850\u001b[0m \u001b[38;5;129m@final\u001b[39m\n\u001b[1;32m   1851\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_python_apply_general\u001b[39m(\n\u001b[1;32m   1852\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1857\u001b[0m     is_agg: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m   1858\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m NDFrameT:\n\u001b[1;32m   1859\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1860\u001b[0m \u001b[38;5;124;03m    Apply function f in python space\u001b[39;00m\n\u001b[1;32m   1861\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1883\u001b[0m \u001b[38;5;124;03m        data after applying f\u001b[39;00m\n\u001b[1;32m   1884\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1885\u001b[0m     values, mutated \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_grouper\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_groupwise\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1886\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m not_indexed_same \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1887\u001b[0m         not_indexed_same \u001b[38;5;241m=\u001b[39m mutated\n",
      "File \u001b[0;32m~/data-literacy-group16/koray/.venv/lib/python3.13/site-packages/pandas/core/groupby/ops.py:919\u001b[0m, in \u001b[0;36mBaseGrouper.apply_groupwise\u001b[0;34m(self, f, data, axis)\u001b[0m\n\u001b[1;32m    917\u001b[0m \u001b[38;5;66;03m# group might be modified\u001b[39;00m\n\u001b[1;32m    918\u001b[0m group_axes \u001b[38;5;241m=\u001b[39m group\u001b[38;5;241m.\u001b[39maxes\n\u001b[0;32m--> 919\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    920\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m mutated \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _is_indexed_like(res, group_axes, axis):\n\u001b[1;32m    921\u001b[0m     mutated \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/data-literacy-group16/koray/.venv/lib/python3.13/site-packages/tqdm/std.py:912\u001b[0m, in \u001b[0;36mtqdm.pandas.<locals>.inner_generator.<locals>.inner.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    906\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    907\u001b[0m     \u001b[38;5;66;03m# update tbar correctly\u001b[39;00m\n\u001b[1;32m    908\u001b[0m     \u001b[38;5;66;03m# it seems `pandas apply` calls `func` twice\u001b[39;00m\n\u001b[1;32m    909\u001b[0m     \u001b[38;5;66;03m# on the first column/row to decide whether it can\u001b[39;00m\n\u001b[1;32m    910\u001b[0m     \u001b[38;5;66;03m# take a fast or slow code path; so stop when t.total==t.n\u001b[39;00m\n\u001b[1;32m    911\u001b[0m     t\u001b[38;5;241m.\u001b[39mupdate(n\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m t\u001b[38;5;241m.\u001b[39mtotal \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mn \u001b[38;5;241m<\u001b[39m t\u001b[38;5;241m.\u001b[39mtotal \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m--> 912\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/data-literacy-group16/koray/feature_calculation/paper_features.py:100\u001b[0m, in \u001b[0;36mFeatureExtractor._extract_features.<locals>._impl\u001b[0;34m(group)\u001b[0m\n\u001b[1;32m     98\u001b[0m         func \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeaturefunctions, func_name)\n\u001b[1;32m     99\u001b[0m         feature_name \u001b[38;5;241m=\u001b[39m func_name[\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mff_\u001b[39m\u001b[38;5;124m\"\u001b[39m):]\n\u001b[0;32m--> 100\u001b[0m         features[feature_name] \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    102\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m pd\u001b[38;5;241m.\u001b[39mSeries(features)\n",
      "Cell \u001b[0;32mIn[22], line 51\u001b[0m, in \u001b[0;36mYourFeatureFunctions.ff_yusuf_idk\u001b[0;34m(review_df, **kwargs)\u001b[0m\n\u001b[1;32m     45\u001b[0m display(review_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m     47\u001b[0m display(review_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: _extract_numeric_prefix(x\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcorrectness\u001b[39m\u001b[38;5;124m'\u001b[39m))))\n\u001b[0;32m---> 51\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthis for testing purposes\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[0;31mAssertionError\u001b[0m: this for testing purposes"
     ]
    }
   ],
   "source": [
    "from koray.feature_calculation.paper_features import FeatureExtractor\n",
    "\n",
    "fe = FeatureExtractor(master_paper_df, master_review_df, master_other_replies_df, YourFeatureFunctions)\n",
    "fe.extract_features()\n",
    "fe.feature_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
