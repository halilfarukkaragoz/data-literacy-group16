# Data Literacy Project - Understanding Disagreement in Peer Review

[Lecture](https://www.mackelab.org/teaching/) on Winter Term 2024/25 at University of Tuebingen.

[Paper Link](./datalit_project_report.pdf)

## Paper Abstract

The peer-review process in major machine learning conferences has long been scrutinized for its subjectiveness, inconsistency and delayed review submissions. In this study, we examine review score discrepancies — instances where a single paper receives highly conflicting evaluations. Concentrating on ICLR 2023 submissions, we introduce a discrepancy metric to quantify disagreements and investigate their prevalence. Furthermore, we explore the interplay between conflicting reviewer scores and confidence levels, and examine how discrepancy relates to subject popularity and future impact. Our analysis aims to uncover underlying structural challenges within the review process and offers insights into potential biases that can hinder the evaluation of innovative work.


## Repo Organization

```sh
|`- busra/                   # time to review deadline analysis
|`- halil/                   # popularity and citation effect analysis
|`- yusuf/                   # discrepancy analysis
|`- koray/                 
|   |`- datastore/        
|   |`- feature_calculation/ # feature calculations
|    `- notebooks/           # correlation analysis 
|    
|`- data/                    # legacy datastore
|`- data_analysis/           # initial feature analysis
|
 `- datalit_project_report.pdf  # Paper
```


## Authors

- [Büşra Asan](https://github.com/busraasan)
- [Halil Faruk Karagöz](https://github.com/halilfarukkaragoz)
- [Koray Ulusan](https://github.com/KorayUlusan)
- [Yusuf Nar](https://github.com/Yusuf-Nar)
