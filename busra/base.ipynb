{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning & Dataframe Prep\n",
    "\n",
    "This notebook handles the following tasks and prepares the data for the analysis.\n",
    "If you something off, please fix it and add it to here.\n",
    "\n",
    "Data Cleaning\n",
    "\n",
    "- Delete NaN entries.\n",
    "- Assign 0: Not Applicable to the Empirical Novelty that has been chosen as \"Not Applicaple\". We have observed that this occurs when reviewers think empirical novelty is not applicaple to a paper, which can be a theoretical one for instance. When calculating the mean of this, please do not include 0 entries.\n",
    "- Ethics Flags include data which says both NO. and Yes, ... All of the contradictory entries included explanations, so we have accepted them as Yes.\n",
    "- Delete reviews submitted after the deadline\n",
    "\n",
    "Data Preparation\n",
    "\n",
    "- Statistics related to each reviewer is calculated for each paper.\n",
    "- These statics are: std, mean, diff(max_score-min_score)\n",
    "\n",
    "### Resulting datasets\n",
    "\n",
    "- review_df_clean -> reviewer per row cleaned data\n",
    "- paper_df -> per paper dataframe, statistics are calculated such as mean, std, variance, max_min difference etc.\n",
    "- df -> basic dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import re\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "file_name = \"../data/ICLR.cc-2023-Conference.csv\"\n",
    "df = pd.read_csv(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = df.columns.str.replace(\"recommendation\", \"score\", regex=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataframe 1: Reviewers as rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score\n",
      "confidence\n",
      "summary_of_the_paper\n",
      "strength_and_weaknesses\n",
      "clarity_quality_novelty_and_reproducibility\n",
      "summary_of_the_review\n",
      "correctness\n",
      "technical_novelty_and_significance\n",
      "empirical_novelty_and_significance\n",
      "flag_for_ethics_review\n",
      "length\n",
      "cdate\n",
      "tmdate\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>keywords</th>\n",
       "      <th>TL;DR</th>\n",
       "      <th>abstract</th>\n",
       "      <th>cdate</th>\n",
       "      <th>tmdate</th>\n",
       "      <th>reviewer1_score</th>\n",
       "      <th>reviewer1_confidence</th>\n",
       "      <th>reviewer1_summary_of_the_paper</th>\n",
       "      <th>reviewer1_strength_and_weaknesses</th>\n",
       "      <th>...</th>\n",
       "      <th>reviewer4_summary_of_the_review</th>\n",
       "      <th>reviewer4_correctness</th>\n",
       "      <th>reviewer4_technical_novelty_and_significance</th>\n",
       "      <th>reviewer4_empirical_novelty_and_significance</th>\n",
       "      <th>reviewer4_flag_for_ethics_review</th>\n",
       "      <th>reviewer4_length</th>\n",
       "      <th>reviewer4_cdate</th>\n",
       "      <th>reviewer4_tmdate</th>\n",
       "      <th>decision</th>\n",
       "      <th>paper_no</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Guiding Safe Exploration with Weakest Precondi...</td>\n",
       "      <td>reinforcement learning; safe learning; safe ex...</td>\n",
       "      <td>We use an online, weakest-precondition-based a...</td>\n",
       "      <td>In reinforcement learning for safety-critical ...</td>\n",
       "      <td>2022-09-22 14:36:24</td>\n",
       "      <td>2024-11-25 10:13:40</td>\n",
       "      <td>6: marginally above the acceptance threshold</td>\n",
       "      <td>4: You are confident in your assessment, but n...</td>\n",
       "      <td>This paper deals with safe exploration in rein...</td>\n",
       "      <td>### Strength\\n- Interesting and importance pro...</td>\n",
       "      <td>...</td>\n",
       "      <td>I like the proposed approach and its associate...</td>\n",
       "      <td>4: All of the claims and statements are well-s...</td>\n",
       "      <td>3: The contributions are significant and somew...</td>\n",
       "      <td>2: The contributions are only marginally signi...</td>\n",
       "      <td>NO.</td>\n",
       "      <td>3082.0</td>\n",
       "      <td>2022-11-03 08:08:39</td>\n",
       "      <td>2022-12-14 03:46:36</td>\n",
       "      <td>Accept: poster</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>An Adaptive Entropy-Regularization Framework f...</td>\n",
       "      <td>Multi-Agent Reinforcement Learning; Entropy Re...</td>\n",
       "      <td>This paper proposes  an adaptive entropy-regul...</td>\n",
       "      <td>In this paper, we propose an adaptive entropy-...</td>\n",
       "      <td>2022-09-22 14:33:17</td>\n",
       "      <td>2023-02-14 00:28:54</td>\n",
       "      <td>3: reject, not good enough</td>\n",
       "      <td>4: You are confident in your assessment, but n...</td>\n",
       "      <td>This paper presents an MARL algorithm to adpat...</td>\n",
       "      <td>### Strengths\\n\\n1. This paper studies adaptiv...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reject</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AutoSparse: Towards Automated Sparse Training</td>\n",
       "      <td>sparsity; sparse training; deep learning</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Sparse training is emerging as a promising ave...</td>\n",
       "      <td>2022-09-22 14:32:39</td>\n",
       "      <td>2023-02-14 00:29:06</td>\n",
       "      <td>5: marginally below the acceptance threshold</td>\n",
       "      <td>4: You are confident in your assessment, but n...</td>\n",
       "      <td>This paper first introduces a technique called...</td>\n",
       "      <td>Strengths:\\n\\n- Provided intuitive examples an...</td>\n",
       "      <td>...</td>\n",
       "      <td>1. The proposed method seems tricky and not el...</td>\n",
       "      <td>2: Several of the paper’s claims are incorrect...</td>\n",
       "      <td>2: The contributions are only marginally signi...</td>\n",
       "      <td>1: The contributions are neither significant n...</td>\n",
       "      <td>NO.</td>\n",
       "      <td>2254.0</td>\n",
       "      <td>2022-10-27 20:14:54</td>\n",
       "      <td>2022-10-27 20:14:54</td>\n",
       "      <td>Reject</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sampling is as easy as learning the score: the...</td>\n",
       "      <td>diffusion models; score-based generative model...</td>\n",
       "      <td>We prove that given an L2-accurate score estim...</td>\n",
       "      <td>We provide theoretical convergence guarantees ...</td>\n",
       "      <td>2022-09-22 14:40:10</td>\n",
       "      <td>2023-02-14 00:27:00</td>\n",
       "      <td>8: accept, good paper</td>\n",
       "      <td>4: You are confident in your assessment, but n...</td>\n",
       "      <td>This paper examines the convergence of SGMs un...</td>\n",
       "      <td>Strength:\\n\\n- The presentation is clear.\\n\\n-...</td>\n",
       "      <td>...</td>\n",
       "      <td>Overall I think the paper introduces very stro...</td>\n",
       "      <td>3: Some of the paper’s claims have minor issue...</td>\n",
       "      <td>3: The contributions are significant and somew...</td>\n",
       "      <td>Not applicable</td>\n",
       "      <td>NO.</td>\n",
       "      <td>5316.0</td>\n",
       "      <td>2022-10-27 22:09:32</td>\n",
       "      <td>2022-10-27 22:09:32</td>\n",
       "      <td>Accept: notable-top-5%</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RoCourseNet: Distributionally Robust Training ...</td>\n",
       "      <td>Counterfactual Explanation; Algorithmic Recour...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Counterfactual (CF) explanations for machine l...</td>\n",
       "      <td>2022-09-22 14:38:43</td>\n",
       "      <td>2024-11-25 10:12:40</td>\n",
       "      <td>3: reject, not good enough</td>\n",
       "      <td>4: You are confident in your assessment, but n...</td>\n",
       "      <td>This submission proposed an approach to solvin...</td>\n",
       "      <td>Strength:\\n\\n1. The paper is easy to follow.\\n...</td>\n",
       "      <td>...</td>\n",
       "      <td>The paper solves an important problem. The exp...</td>\n",
       "      <td>4: All of the claims and statements are well-s...</td>\n",
       "      <td>2: The contributions are only marginally signi...</td>\n",
       "      <td>2: The contributions are only marginally signi...</td>\n",
       "      <td>NO.</td>\n",
       "      <td>2937.0</td>\n",
       "      <td>2022-10-29 20:23:57</td>\n",
       "      <td>2022-10-29 20:23:57</td>\n",
       "      <td>Reject</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 60 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  Guiding Safe Exploration with Weakest Precondi...   \n",
       "1  An Adaptive Entropy-Regularization Framework f...   \n",
       "2      AutoSparse: Towards Automated Sparse Training   \n",
       "3  Sampling is as easy as learning the score: the...   \n",
       "4  RoCourseNet: Distributionally Robust Training ...   \n",
       "\n",
       "                                            keywords  \\\n",
       "0  reinforcement learning; safe learning; safe ex...   \n",
       "1  Multi-Agent Reinforcement Learning; Entropy Re...   \n",
       "2           sparsity; sparse training; deep learning   \n",
       "3  diffusion models; score-based generative model...   \n",
       "4  Counterfactual Explanation; Algorithmic Recour...   \n",
       "\n",
       "                                               TL;DR  \\\n",
       "0  We use an online, weakest-precondition-based a...   \n",
       "1  This paper proposes  an adaptive entropy-regul...   \n",
       "2                                                NaN   \n",
       "3  We prove that given an L2-accurate score estim...   \n",
       "4                                                NaN   \n",
       "\n",
       "                                            abstract                cdate  \\\n",
       "0  In reinforcement learning for safety-critical ...  2022-09-22 14:36:24   \n",
       "1  In this paper, we propose an adaptive entropy-...  2022-09-22 14:33:17   \n",
       "2  Sparse training is emerging as a promising ave...  2022-09-22 14:32:39   \n",
       "3  We provide theoretical convergence guarantees ...  2022-09-22 14:40:10   \n",
       "4  Counterfactual (CF) explanations for machine l...  2022-09-22 14:38:43   \n",
       "\n",
       "                tmdate                               reviewer1_score  \\\n",
       "0  2024-11-25 10:13:40  6: marginally above the acceptance threshold   \n",
       "1  2023-02-14 00:28:54                    3: reject, not good enough   \n",
       "2  2023-02-14 00:29:06  5: marginally below the acceptance threshold   \n",
       "3  2023-02-14 00:27:00                         8: accept, good paper   \n",
       "4  2024-11-25 10:12:40                    3: reject, not good enough   \n",
       "\n",
       "                                reviewer1_confidence  \\\n",
       "0  4: You are confident in your assessment, but n...   \n",
       "1  4: You are confident in your assessment, but n...   \n",
       "2  4: You are confident in your assessment, but n...   \n",
       "3  4: You are confident in your assessment, but n...   \n",
       "4  4: You are confident in your assessment, but n...   \n",
       "\n",
       "                      reviewer1_summary_of_the_paper  \\\n",
       "0  This paper deals with safe exploration in rein...   \n",
       "1  This paper presents an MARL algorithm to adpat...   \n",
       "2  This paper first introduces a technique called...   \n",
       "3  This paper examines the convergence of SGMs un...   \n",
       "4  This submission proposed an approach to solvin...   \n",
       "\n",
       "                   reviewer1_strength_and_weaknesses  ...  \\\n",
       "0  ### Strength\\n- Interesting and importance pro...  ...   \n",
       "1  ### Strengths\\n\\n1. This paper studies adaptiv...  ...   \n",
       "2  Strengths:\\n\\n- Provided intuitive examples an...  ...   \n",
       "3  Strength:\\n\\n- The presentation is clear.\\n\\n-...  ...   \n",
       "4  Strength:\\n\\n1. The paper is easy to follow.\\n...  ...   \n",
       "\n",
       "                     reviewer4_summary_of_the_review  \\\n",
       "0  I like the proposed approach and its associate...   \n",
       "1                                                NaN   \n",
       "2  1. The proposed method seems tricky and not el...   \n",
       "3  Overall I think the paper introduces very stro...   \n",
       "4  The paper solves an important problem. The exp...   \n",
       "\n",
       "                               reviewer4_correctness  \\\n",
       "0  4: All of the claims and statements are well-s...   \n",
       "1                                                NaN   \n",
       "2  2: Several of the paper’s claims are incorrect...   \n",
       "3  3: Some of the paper’s claims have minor issue...   \n",
       "4  4: All of the claims and statements are well-s...   \n",
       "\n",
       "        reviewer4_technical_novelty_and_significance  \\\n",
       "0  3: The contributions are significant and somew...   \n",
       "1                                                NaN   \n",
       "2  2: The contributions are only marginally signi...   \n",
       "3  3: The contributions are significant and somew...   \n",
       "4  2: The contributions are only marginally signi...   \n",
       "\n",
       "        reviewer4_empirical_novelty_and_significance  \\\n",
       "0  2: The contributions are only marginally signi...   \n",
       "1                                                NaN   \n",
       "2  1: The contributions are neither significant n...   \n",
       "3                                     Not applicable   \n",
       "4  2: The contributions are only marginally signi...   \n",
       "\n",
       "  reviewer4_flag_for_ethics_review reviewer4_length      reviewer4_cdate  \\\n",
       "0                              NO.           3082.0  2022-11-03 08:08:39   \n",
       "1                              NaN              NaN                  NaN   \n",
       "2                              NO.           2254.0  2022-10-27 20:14:54   \n",
       "3                              NO.           5316.0  2022-10-27 22:09:32   \n",
       "4                              NO.           2937.0  2022-10-29 20:23:57   \n",
       "\n",
       "      reviewer4_tmdate                decision paper_no  \n",
       "0  2022-12-14 03:46:36          Accept: poster        0  \n",
       "1                  NaN                  Reject        1  \n",
       "2  2022-10-27 20:14:54                  Reject        2  \n",
       "3  2022-10-27 22:09:32  Accept: notable-top-5%        3  \n",
       "4  2022-10-29 20:23:57                  Reject        4  \n",
       "\n",
       "[5 rows x 60 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instead of one row per paper, arrange data to have one reviewer per row.\n",
    "\n",
    "reviewer_feature_cols = [col.split('reviewer1_')[1] for col in df.columns if col.startswith('reviewer1')]\n",
    "for i in reviewer_feature_cols:\n",
    "    print(i)\n",
    "reviewer_cols = [col for col in df.columns for i in range(1, 5) if col.startswith('reviewer' + str(i) + '_')]\n",
    "non_reviewer_cols = [col for col in df.columns if col not in reviewer_cols]\n",
    "\n",
    "\n",
    "df['paper_id'] = np.arange(len(df))\n",
    "review_df = pd.DataFrame(columns=['paper_id', 'reviewer', 'reviewer_score', 'reviewer_confidence', 'reviewer_summary_of_the_paper', 'reviewer_strength_and_weaknesses', 'reviewer_clarity_quality_novelty_and_reproducibility', 'reviewer_summary_of_the_review', 'reviewer_correctness', 'reviewer_technical_novelty_and_significance', 'reviewer_empirical_novelty_and_significance', 'reviewer_flag_for_ethics_review', 'reviewer_length', 'reviewer_cdate', 'reviewer_tmdate', 'title', 'keywords', 'TL;DR', 'abstract', 'cdate', 'tmdate', 'decision'])\n",
    "for idx, row in df.iterrows():\n",
    "    for i in range(1, 5):\n",
    "        dict_ = {}\n",
    "        for col in reviewer_feature_cols:\n",
    "            dict_['reviewer'] = i\n",
    "            dict_['reviewer' + '_' + col] = row['reviewer' + str(i) + '_' + col]\n",
    "        for col in non_reviewer_cols:\n",
    "            dict_[col] = row[col]\n",
    "        dict_['paper_id'] = row['paper_id']\n",
    "        review_df.loc[len(review_df)] = dict_\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data prep: convert and simplify column values \n",
    "\n",
    "1. Convert cdate to pandas datetime datatype.\n",
    "2. Add time_to_deadline column which measures the time difference between the review submission and review deadline\n",
    "3. To get the score part, remove the explanations from score columns such as recommendation.\n",
    "4. Add a is_high_variance column to detect high discrepancy reviews.\n",
    "5. There are different acceptances, like top-5-notable etc. We just treat them as expected, so simply those explanations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['reviewer1_cdate'] = pd.to_datetime(df['reviewer1_cdate'])\n",
    "df['reviewer2_cdate'] = pd.to_datetime(df['reviewer2_cdate'])\n",
    "df['reviewer3_cdate'] = pd.to_datetime(df['reviewer3_cdate'])\n",
    "df['reviewer4_cdate'] = pd.to_datetime(df['reviewer4_cdate'])\n",
    "\n",
    "df['reviewer1_time_to_deadline'] = pd.to_datetime('2022-11-05 01:00:00') - df['reviewer1_cdate']\n",
    "df['reviewer2_time_to_deadline'] = pd.to_datetime('2022-11-05 01:00:00') - df['reviewer2_cdate']\n",
    "df['reviewer3_time_to_deadline'] = pd.to_datetime('2022-11-05 01:00:00') - df['reviewer3_cdate']\n",
    "df['reviewer4_time_to_deadline'] = pd.to_datetime('2022-11-05 01:00:00') - df['reviewer4_cdate']\n",
    "\n",
    "df.dropna(subset=['reviewer1_cdate', 'reviewer2_cdate', 'reviewer3_cdate', 'reviewer4_cdate'], how='all', inplace=True)\n",
    "\n",
    "def get_scores_from_str(x):\n",
    "    if isinstance(x, str):\n",
    "        return int(x.split(':')[0])\n",
    "    else:\n",
    "        return np.nan\n",
    "    \n",
    "df['reviewer1_score'] = df['reviewer1_score'].apply(lambda x: get_scores_from_str(x))\n",
    "df['reviewer2_score'] = df['reviewer2_score'].apply(lambda x: get_scores_from_str(x))\n",
    "df['reviewer3_score'] = df['reviewer3_score'].apply(lambda x: get_scores_from_str(x))\n",
    "df['reviewer4_score'] = df['reviewer4_score'].apply(lambda x: get_scores_from_str(x))\n",
    "\n",
    "df['max_score'] = df[['reviewer1_score', 'reviewer2_score', 'reviewer3_score', 'reviewer4_score']].max(axis=1)\n",
    "df['min_score'] = df[['reviewer1_score', 'reviewer2_score', 'reviewer3_score', 'reviewer4_score']].min(axis=1)\n",
    "df['max_min_score_diff'] = df['max_score'] - df['min_score']\n",
    "\n",
    "df['is_high_variance'] = df['max_min_score_diff'] >= 4\n",
    "\n",
    "df['decision'] = df['decision'].apply(lambda x: \"Accept\" if \"accept\" in x.lower() else \"Reject\")\n",
    "\n",
    "df['max_score'] = df[['reviewer1_score', 'reviewer2_score', 'reviewer3_score', 'reviewer4_score']].max(axis=1)\n",
    "df['min_score'] = df[['reviewer1_score', 'reviewer2_score', 'reviewer3_score', 'reviewer4_score']].min(axis=1)\n",
    "df['max_min_score_diff'] = df['max_score'] - df['min_score']\n",
    "\n",
    "df['is_high_variance'] = df['max_min_score_diff'] >= 4\n",
    "\n",
    "df['decision'] = df['decision'].apply(lambda x: \"Accept\" if \"accept\" in x.lower() else \"Reject\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Play with variables and check if the values are as expected:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>keywords</th>\n",
       "      <th>TL;DR</th>\n",
       "      <th>abstract</th>\n",
       "      <th>cdate</th>\n",
       "      <th>tmdate</th>\n",
       "      <th>reviewer1_score</th>\n",
       "      <th>reviewer1_confidence</th>\n",
       "      <th>reviewer1_summary_of_the_paper</th>\n",
       "      <th>reviewer1_strength_and_weaknesses</th>\n",
       "      <th>...</th>\n",
       "      <th>decision</th>\n",
       "      <th>paper_no</th>\n",
       "      <th>reviewer1_time_to_deadline</th>\n",
       "      <th>reviewer2_time_to_deadline</th>\n",
       "      <th>reviewer3_time_to_deadline</th>\n",
       "      <th>reviewer4_time_to_deadline</th>\n",
       "      <th>max_score</th>\n",
       "      <th>min_score</th>\n",
       "      <th>max_min_score_diff</th>\n",
       "      <th>is_high_variance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>PD-MORL: Preference-Driven Multi-Objective Rei...</td>\n",
       "      <td>multi-objective reinforcement learning; MORL; ...</td>\n",
       "      <td>A novel approach that obtains a single policy ...</td>\n",
       "      <td>Multi-objective reinforcement learning (MORL) ...</td>\n",
       "      <td>2022-09-22 14:37:04</td>\n",
       "      <td>2023-03-02 03:46:32</td>\n",
       "      <td>8</td>\n",
       "      <td>3: You are fairly confident in your assessment...</td>\n",
       "      <td>This work proposes an algorithm for solving mu...</td>\n",
       "      <td>The main strengths of this paper:\\n- Novel app...</td>\n",
       "      <td>...</td>\n",
       "      <td>Accept</td>\n",
       "      <td>32</td>\n",
       "      <td>11 days 07:56:58</td>\n",
       "      <td>10 days 08:47:26</td>\n",
       "      <td>8 days 00:55:32</td>\n",
       "      <td>2 days 05:53:11</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>CircNet: Meshing 3D Point Clouds with Circumce...</td>\n",
       "      <td>Meshing; 3D Point Cloud; Point Cloud Triangula...</td>\n",
       "      <td>We present a deep neural architecture that det...</td>\n",
       "      <td>Reconstructing 3D point clouds into triangle m...</td>\n",
       "      <td>2022-09-22 14:34:26</td>\n",
       "      <td>2024-11-25 10:14:38</td>\n",
       "      <td>8</td>\n",
       "      <td>4: You are confident in your assessment, but n...</td>\n",
       "      <td>This paper tackles the problem of point cloud ...</td>\n",
       "      <td>Strength\\n+ The formulation of the problem as ...</td>\n",
       "      <td>...</td>\n",
       "      <td>Accept</td>\n",
       "      <td>33</td>\n",
       "      <td>15 days 11:46:51</td>\n",
       "      <td>13 days 09:18:49</td>\n",
       "      <td>0 days 01:53:56</td>\n",
       "      <td>-2 days +00:26:53</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Semi-supervised learning with a principled lik...</td>\n",
       "      <td>Bayesian deep learning; Bayesian neural networ...</td>\n",
       "      <td>We develop Bayesian semi-supervised learning, ...</td>\n",
       "      <td>We currently do not have an understanding of s...</td>\n",
       "      <td>2022-09-22 14:34:48</td>\n",
       "      <td>2023-02-21 09:35:10</td>\n",
       "      <td>5</td>\n",
       "      <td>4: You are confident in your assessment, but n...</td>\n",
       "      <td>The authors consider the fact that our common ...</td>\n",
       "      <td>## Strengths\\nThe paper is well argued for and...</td>\n",
       "      <td>...</td>\n",
       "      <td>Accept</td>\n",
       "      <td>34</td>\n",
       "      <td>16 days 15:04:34</td>\n",
       "      <td>10 days 04:45:05</td>\n",
       "      <td>10 days 01:48:15</td>\n",
       "      <td>7 days 20:28:22</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Is Adversarial Training Really a Silver Bullet...</td>\n",
       "      <td>Data poisoning; adversarial training; indiscri...</td>\n",
       "      <td>We propose an indiscriminative feature-based p...</td>\n",
       "      <td>Indiscriminate data poisoning can decrease the...</td>\n",
       "      <td>2022-09-22 14:36:10</td>\n",
       "      <td>2023-03-02 17:30:28</td>\n",
       "      <td>6</td>\n",
       "      <td>4: You are confident in your assessment, but n...</td>\n",
       "      <td>In this work the authors attack in models in t...</td>\n",
       "      <td>Strengths:\\n* The method is novel and obtains ...</td>\n",
       "      <td>...</td>\n",
       "      <td>Accept</td>\n",
       "      <td>37</td>\n",
       "      <td>11 days 15:48:46</td>\n",
       "      <td>11 days 07:24:56</td>\n",
       "      <td>10 days 03:36:11</td>\n",
       "      <td>7 days 22:02:29</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>Red PANDA: Disambiguating Image Anomaly Detect...</td>\n",
       "      <td>Anomaly Detection; Disentanglement</td>\n",
       "      <td>Proposing a new anomaly detection setting when...</td>\n",
       "      <td>Anomaly detection methods strive to discover p...</td>\n",
       "      <td>2022-09-22 14:35:53</td>\n",
       "      <td>2023-03-02 12:44:02</td>\n",
       "      <td>6</td>\n",
       "      <td>3: You are fairly confident in your assessment...</td>\n",
       "      <td>This paper concerns anomaly detection. In part...</td>\n",
       "      <td># Strengths\\n* Anomaly detection is an interes...</td>\n",
       "      <td>...</td>\n",
       "      <td>Accept</td>\n",
       "      <td>55</td>\n",
       "      <td>15 days 13:28:45</td>\n",
       "      <td>9 days 21:32:44</td>\n",
       "      <td>8 days 18:47:58</td>\n",
       "      <td>4 days 10:41:23</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3678</th>\n",
       "      <td>DDM$^2$: Self-Supervised Diffusion MRI Denoisi...</td>\n",
       "      <td>Unsupervised MRI Denoising; Diffusion Models</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Magnetic resonance imaging (MRI) is a common a...</td>\n",
       "      <td>2022-09-22 14:31:21</td>\n",
       "      <td>2024-11-25 10:16:17</td>\n",
       "      <td>1</td>\n",
       "      <td>5: You are absolutely certain about your asses...</td>\n",
       "      <td>The paper proposes a new method for denoising ...</td>\n",
       "      <td>Strengths\\n\\nThe proposed method makes use of ...</td>\n",
       "      <td>...</td>\n",
       "      <td>Accept</td>\n",
       "      <td>3678</td>\n",
       "      <td>10 days 21:33:32</td>\n",
       "      <td>10 days 13:51:50</td>\n",
       "      <td>3 days 20:27:53</td>\n",
       "      <td>3 days 11:06:24</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3743</th>\n",
       "      <td>SeaFormer: Squeeze-enhanced Axial Transformer ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Since the introduction of Vision Transformers,...</td>\n",
       "      <td>2022-09-22 14:32:03</td>\n",
       "      <td>2024-11-25 10:15:52</td>\n",
       "      <td>8</td>\n",
       "      <td>2: You are willing to defend your assessment, ...</td>\n",
       "      <td>this paper presents SeaFormer: a new transform...</td>\n",
       "      <td>Strength:\\n- The proposed transformer is O(WH)...</td>\n",
       "      <td>...</td>\n",
       "      <td>Accept</td>\n",
       "      <td>3743</td>\n",
       "      <td>11 days 16:43:04</td>\n",
       "      <td>11 days 10:33:00</td>\n",
       "      <td>10 days 21:16:35</td>\n",
       "      <td>10 days 13:05:09</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3746</th>\n",
       "      <td>Neural Image-based Avatars: Generalizable Radi...</td>\n",
       "      <td>Generalizable human radiance fields; Human per...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>We present a method that enables synthesizing ...</td>\n",
       "      <td>2022-09-22 14:41:21</td>\n",
       "      <td>2024-11-25 10:11:30</td>\n",
       "      <td>8</td>\n",
       "      <td>3: You are fairly confident in your assessment...</td>\n",
       "      <td>The authors propose Neural Image-based Avatars...</td>\n",
       "      <td>Main Strengths:\\n- The method gathers two comp...</td>\n",
       "      <td>...</td>\n",
       "      <td>Accept</td>\n",
       "      <td>3746</td>\n",
       "      <td>12 days 04:53:49</td>\n",
       "      <td>11 days 06:41:01</td>\n",
       "      <td>11 days 06:18:10</td>\n",
       "      <td>10 days 13:31:56</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3752</th>\n",
       "      <td>Approximate Nearest Neighbor Search through Mo...</td>\n",
       "      <td>Similarity Search; Nearest-Neighbor Search; Po...</td>\n",
       "      <td>Using modern error-correcting codes, we presen...</td>\n",
       "      <td>A locality-sensitive hash (or LSH) is a functi...</td>\n",
       "      <td>2022-09-22 14:33:10</td>\n",
       "      <td>2023-02-14 10:50:31</td>\n",
       "      <td>6</td>\n",
       "      <td>3: You are fairly confident in your assessment...</td>\n",
       "      <td>In this paper, the authors investigate a probl...</td>\n",
       "      <td>The paper has the following strengths:\\n\\nS1. ...</td>\n",
       "      <td>...</td>\n",
       "      <td>Accept</td>\n",
       "      <td>3752</td>\n",
       "      <td>12 days 07:05:11</td>\n",
       "      <td>11 days 19:32:23</td>\n",
       "      <td>10 days 21:57:58</td>\n",
       "      <td>0 days 03:50:56</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3760</th>\n",
       "      <td>Modeling Sequential Sentence Relation to Impro...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Recently multi-lingual pre-trained language mo...</td>\n",
       "      <td>2022-09-22 14:33:02</td>\n",
       "      <td>2023-03-02 06:12:41</td>\n",
       "      <td>6</td>\n",
       "      <td>4: You are confident in your assessment, but n...</td>\n",
       "      <td>The paper presents a contrastive learning appr...</td>\n",
       "      <td>Strengths\\n1. The paper is well-written and ex...</td>\n",
       "      <td>...</td>\n",
       "      <td>Accept</td>\n",
       "      <td>3760</td>\n",
       "      <td>14 days 14:41:17</td>\n",
       "      <td>11 days 18:40:57</td>\n",
       "      <td>9 days 23:04:23</td>\n",
       "      <td>8 days 11:53:54</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>168 rows × 68 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  title  \\\n",
       "32    PD-MORL: Preference-Driven Multi-Objective Rei...   \n",
       "33    CircNet: Meshing 3D Point Clouds with Circumce...   \n",
       "34    Semi-supervised learning with a principled lik...   \n",
       "37    Is Adversarial Training Really a Silver Bullet...   \n",
       "55    Red PANDA: Disambiguating Image Anomaly Detect...   \n",
       "...                                                 ...   \n",
       "3678  DDM$^2$: Self-Supervised Diffusion MRI Denoisi...   \n",
       "3743  SeaFormer: Squeeze-enhanced Axial Transformer ...   \n",
       "3746  Neural Image-based Avatars: Generalizable Radi...   \n",
       "3752  Approximate Nearest Neighbor Search through Mo...   \n",
       "3760  Modeling Sequential Sentence Relation to Impro...   \n",
       "\n",
       "                                               keywords  \\\n",
       "32    multi-objective reinforcement learning; MORL; ...   \n",
       "33    Meshing; 3D Point Cloud; Point Cloud Triangula...   \n",
       "34    Bayesian deep learning; Bayesian neural networ...   \n",
       "37    Data poisoning; adversarial training; indiscri...   \n",
       "55                   Anomaly Detection; Disentanglement   \n",
       "...                                                 ...   \n",
       "3678       Unsupervised MRI Denoising; Diffusion Models   \n",
       "3743                                                NaN   \n",
       "3746  Generalizable human radiance fields; Human per...   \n",
       "3752  Similarity Search; Nearest-Neighbor Search; Po...   \n",
       "3760                                                NaN   \n",
       "\n",
       "                                                  TL;DR  \\\n",
       "32    A novel approach that obtains a single policy ...   \n",
       "33    We present a deep neural architecture that det...   \n",
       "34    We develop Bayesian semi-supervised learning, ...   \n",
       "37    We propose an indiscriminative feature-based p...   \n",
       "55    Proposing a new anomaly detection setting when...   \n",
       "...                                                 ...   \n",
       "3678                                                NaN   \n",
       "3743                                                NaN   \n",
       "3746                                                NaN   \n",
       "3752  Using modern error-correcting codes, we presen...   \n",
       "3760                                                NaN   \n",
       "\n",
       "                                               abstract                cdate  \\\n",
       "32    Multi-objective reinforcement learning (MORL) ...  2022-09-22 14:37:04   \n",
       "33    Reconstructing 3D point clouds into triangle m...  2022-09-22 14:34:26   \n",
       "34    We currently do not have an understanding of s...  2022-09-22 14:34:48   \n",
       "37    Indiscriminate data poisoning can decrease the...  2022-09-22 14:36:10   \n",
       "55    Anomaly detection methods strive to discover p...  2022-09-22 14:35:53   \n",
       "...                                                 ...                  ...   \n",
       "3678  Magnetic resonance imaging (MRI) is a common a...  2022-09-22 14:31:21   \n",
       "3743  Since the introduction of Vision Transformers,...  2022-09-22 14:32:03   \n",
       "3746  We present a method that enables synthesizing ...  2022-09-22 14:41:21   \n",
       "3752  A locality-sensitive hash (or LSH) is a functi...  2022-09-22 14:33:10   \n",
       "3760  Recently multi-lingual pre-trained language mo...  2022-09-22 14:33:02   \n",
       "\n",
       "                   tmdate  reviewer1_score  \\\n",
       "32    2023-03-02 03:46:32                8   \n",
       "33    2024-11-25 10:14:38                8   \n",
       "34    2023-02-21 09:35:10                5   \n",
       "37    2023-03-02 17:30:28                6   \n",
       "55    2023-03-02 12:44:02                6   \n",
       "...                   ...              ...   \n",
       "3678  2024-11-25 10:16:17                1   \n",
       "3743  2024-11-25 10:15:52                8   \n",
       "3746  2024-11-25 10:11:30                8   \n",
       "3752  2023-02-14 10:50:31                6   \n",
       "3760  2023-03-02 06:12:41                6   \n",
       "\n",
       "                                   reviewer1_confidence  \\\n",
       "32    3: You are fairly confident in your assessment...   \n",
       "33    4: You are confident in your assessment, but n...   \n",
       "34    4: You are confident in your assessment, but n...   \n",
       "37    4: You are confident in your assessment, but n...   \n",
       "55    3: You are fairly confident in your assessment...   \n",
       "...                                                 ...   \n",
       "3678  5: You are absolutely certain about your asses...   \n",
       "3743  2: You are willing to defend your assessment, ...   \n",
       "3746  3: You are fairly confident in your assessment...   \n",
       "3752  3: You are fairly confident in your assessment...   \n",
       "3760  4: You are confident in your assessment, but n...   \n",
       "\n",
       "                         reviewer1_summary_of_the_paper  \\\n",
       "32    This work proposes an algorithm for solving mu...   \n",
       "33    This paper tackles the problem of point cloud ...   \n",
       "34    The authors consider the fact that our common ...   \n",
       "37    In this work the authors attack in models in t...   \n",
       "55    This paper concerns anomaly detection. In part...   \n",
       "...                                                 ...   \n",
       "3678  The paper proposes a new method for denoising ...   \n",
       "3743  this paper presents SeaFormer: a new transform...   \n",
       "3746  The authors propose Neural Image-based Avatars...   \n",
       "3752  In this paper, the authors investigate a probl...   \n",
       "3760  The paper presents a contrastive learning appr...   \n",
       "\n",
       "                      reviewer1_strength_and_weaknesses  ... decision  \\\n",
       "32    The main strengths of this paper:\\n- Novel app...  ...   Accept   \n",
       "33    Strength\\n+ The formulation of the problem as ...  ...   Accept   \n",
       "34    ## Strengths\\nThe paper is well argued for and...  ...   Accept   \n",
       "37    Strengths:\\n* The method is novel and obtains ...  ...   Accept   \n",
       "55    # Strengths\\n* Anomaly detection is an interes...  ...   Accept   \n",
       "...                                                 ...  ...      ...   \n",
       "3678  Strengths\\n\\nThe proposed method makes use of ...  ...   Accept   \n",
       "3743  Strength:\\n- The proposed transformer is O(WH)...  ...   Accept   \n",
       "3746  Main Strengths:\\n- The method gathers two comp...  ...   Accept   \n",
       "3752  The paper has the following strengths:\\n\\nS1. ...  ...   Accept   \n",
       "3760  Strengths\\n1. The paper is well-written and ex...  ...   Accept   \n",
       "\n",
       "     paper_no reviewer1_time_to_deadline reviewer2_time_to_deadline  \\\n",
       "32         32           11 days 07:56:58           10 days 08:47:26   \n",
       "33         33           15 days 11:46:51           13 days 09:18:49   \n",
       "34         34           16 days 15:04:34           10 days 04:45:05   \n",
       "37         37           11 days 15:48:46           11 days 07:24:56   \n",
       "55         55           15 days 13:28:45            9 days 21:32:44   \n",
       "...       ...                        ...                        ...   \n",
       "3678     3678           10 days 21:33:32           10 days 13:51:50   \n",
       "3743     3743           11 days 16:43:04           11 days 10:33:00   \n",
       "3746     3746           12 days 04:53:49           11 days 06:41:01   \n",
       "3752     3752           12 days 07:05:11           11 days 19:32:23   \n",
       "3760     3760           14 days 14:41:17           11 days 18:40:57   \n",
       "\n",
       "     reviewer3_time_to_deadline reviewer4_time_to_deadline  max_score  \\\n",
       "32              8 days 00:55:32            2 days 05:53:11          8   \n",
       "33              0 days 01:53:56          -2 days +00:26:53          8   \n",
       "34             10 days 01:48:15            7 days 20:28:22          8   \n",
       "37             10 days 03:36:11            7 days 22:02:29         10   \n",
       "55              8 days 18:47:58            4 days 10:41:23          6   \n",
       "...                         ...                        ...        ...   \n",
       "3678            3 days 20:27:53            3 days 11:06:24          8   \n",
       "3743           10 days 21:16:35           10 days 13:05:09          8   \n",
       "3746           11 days 06:18:10           10 days 13:31:56          8   \n",
       "3752           10 days 21:57:58            0 days 03:50:56          8   \n",
       "3760            9 days 23:04:23            8 days 11:53:54          8   \n",
       "\n",
       "     min_score max_min_score_diff  is_high_variance  \n",
       "32           3                  5              True  \n",
       "33           3                  5              True  \n",
       "34           3                  5              True  \n",
       "37           6                  4              True  \n",
       "55           1                  5              True  \n",
       "...        ...                ...               ...  \n",
       "3678         1                  7              True  \n",
       "3743         3                  5              True  \n",
       "3746         3                  5              True  \n",
       "3752         3                  5              True  \n",
       "3760         3                  5              True  \n",
       "\n",
       "[168 rows x 68 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['decision'].eq(\"Accept\") & df['is_high_variance']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewer1_score</th>\n",
       "      <th>reviewer2_score</th>\n",
       "      <th>reviewer3_score</th>\n",
       "      <th>reviewer4_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3789</th>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3790</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3792</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3793</th>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3794</th>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2628 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      reviewer1_score  reviewer2_score  reviewer3_score  reviewer4_score\n",
       "0                   6                8                6                6\n",
       "2                   5                6                3                3\n",
       "3                   8                8                8                8\n",
       "4                   3                3                3                6\n",
       "5                   6                6                3                3\n",
       "...               ...              ...              ...              ...\n",
       "3789                6                6                6                6\n",
       "3790                3                3                3                3\n",
       "3792                1                6                6                3\n",
       "3793                6                6                8                6\n",
       "3794                6                3                3                3\n",
       "\n",
       "[2628 rows x 4 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['reviewer1_score', 'reviewer2_score', 'reviewer3_score', 'reviewer4_score']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Clean reviews submitted after the deadline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/fl/8ng_m3ld6734_9svpd_k619m0000gn/T/ipykernel_69394/3064297660.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  review_df_clean.dropna(subset=['reviewer_cdate'], inplace=True)\n"
     ]
    }
   ],
   "source": [
    "review_df['reviewer_cdate'] = pd.to_datetime(review_df['reviewer_cdate'])\n",
    "review_df_clean = review_df[review_df['reviewer_cdate'] < pd.to_datetime('2022-11-05 01:00:00')]\n",
    "review_df_clean.dropna(subset=['reviewer_cdate'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Treat contradictiory ethis flags as Yes, because all of them include explanation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/fl/8ng_m3ld6734_9svpd_k619m0000gn/T/ipykernel_69394/2241807063.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  review_df_clean['reviewer_flag_for_ethics_review'] = review_df_clean['reviewer_flag_for_ethics_review'].apply(lambda x: 1 if 'yes' in str(x).lower() else 0)\n"
     ]
    }
   ],
   "source": [
    "review_df_clean.value_counts('reviewer_flag_for_ethics_review')\n",
    "review_df_clean['reviewer_flag_for_ethics_review'] = review_df_clean['reviewer_flag_for_ethics_review'].apply(lambda x: 1 if 'yes' in str(x).lower() else 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Assign 0 to Not applicaple papers for Empirical Novelty and Significance. These are generally treated as theoretical papers by the reviewers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reviewer_empirical_novelty_and_significance\n",
      "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.    5895\n",
      "2: The contributions are only marginally significant or novel.                                              5270\n",
      "Not applicable                                                                                              1075\n",
      "4: The contributions are significant, and do not exist in prior works.                                      1018\n",
      "1: The contributions are neither significant nor novel.                                                      621\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/fl/8ng_m3ld6734_9svpd_k619m0000gn/T/ipykernel_69394/2876056155.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  review_df_clean['reviewer_empirical_novelty_and_significance'] = review_df_clean['reviewer_empirical_novelty_and_significance'].apply(lambda x: \"0: Not Applicable\" if x == \"Not applicable\" else x)\n"
     ]
    }
   ],
   "source": [
    "print(review_df_clean['reviewer_empirical_novelty_and_significance'].value_counts())\n",
    "review_df_clean['reviewer_empirical_novelty_and_significance'] = review_df_clean['reviewer_empirical_novelty_and_significance'].apply(lambda x: \"0: Not Applicable\" if x == \"Not applicable\" else x)\n",
    "review_df_clean['reviewer_empirical_novelty_and_significance'].value_counts()\n",
    "\n",
    "review_df_clean.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Add time_to_deadline column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/fl/8ng_m3ld6734_9svpd_k619m0000gn/T/ipykernel_69394/2658128959.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  review_df_clean['time_to_deadline'] = pd.to_datetime('2022-11-05 01:00:00') - review_df_clean['reviewer_cdate']\n"
     ]
    }
   ],
   "source": [
    "review_df_clean['time_to_deadline'] = pd.to_datetime('2022-11-05 01:00:00') - review_df_clean['reviewer_cdate']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Convert string numbers to integers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/fl/8ng_m3ld6734_9svpd_k619m0000gn/T/ipykernel_69394/3490803434.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  review_df_clean['review_confidence'] = review_df_clean['reviewer_confidence'].apply(lambda x: x.split(':')[0].strip() if pd.notnull(x) else x).astype(int)\n",
      "/var/folders/fl/8ng_m3ld6734_9svpd_k619m0000gn/T/ipykernel_69394/3490803434.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  review_df_clean.drop(columns=['reviewer_confidence'], inplace=True)\n",
      "/var/folders/fl/8ng_m3ld6734_9svpd_k619m0000gn/T/ipykernel_69394/3490803434.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  review_df_clean['review_score'] = review_df_clean['reviewer_score'].apply(lambda x: x.split(':')[0].strip() if pd.notnull(x) else x).astype(int)\n",
      "/var/folders/fl/8ng_m3ld6734_9svpd_k619m0000gn/T/ipykernel_69394/3490803434.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  review_df_clean.drop(columns=['reviewer_score'], inplace=True)\n",
      "/var/folders/fl/8ng_m3ld6734_9svpd_k619m0000gn/T/ipykernel_69394/3490803434.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  review_df_clean['review_correctness'] = review_df_clean['reviewer_correctness'].apply(lambda x: x.split(':')[0].strip() if pd.notnull(x) else x).astype(int)\n",
      "/var/folders/fl/8ng_m3ld6734_9svpd_k619m0000gn/T/ipykernel_69394/3490803434.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  review_df_clean.drop(columns=['reviewer_correctness'], inplace=True)\n",
      "/var/folders/fl/8ng_m3ld6734_9svpd_k619m0000gn/T/ipykernel_69394/3490803434.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  review_df_clean['review_technical_novelty_and_significance'] = review_df_clean['reviewer_technical_novelty_and_significance'].apply(lambda x: x.split(':')[0].strip() if pd.notnull(x) else x).astype(int)\n",
      "/var/folders/fl/8ng_m3ld6734_9svpd_k619m0000gn/T/ipykernel_69394/3490803434.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  review_df_clean.drop(columns=['reviewer_technical_novelty_and_significance'], inplace=True)\n",
      "/var/folders/fl/8ng_m3ld6734_9svpd_k619m0000gn/T/ipykernel_69394/3490803434.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  review_df_clean['review_empirical_novelty_and_significance'] = review_df_clean['reviewer_empirical_novelty_and_significance'].apply(lambda x: x.split(':')[0].strip() if pd.notnull(x) else x).astype(int)\n",
      "/var/folders/fl/8ng_m3ld6734_9svpd_k619m0000gn/T/ipykernel_69394/3490803434.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  review_df_clean.drop(columns=['reviewer_empirical_novelty_and_significance'], inplace=True)\n"
     ]
    }
   ],
   "source": [
    "review_df_clean['review_confidence'] = review_df_clean['reviewer_confidence'].apply(lambda x: x.split(':')[0].strip() if pd.notnull(x) else x).astype(int)\n",
    "review_df_clean.drop(columns=['reviewer_confidence'], inplace=True)\n",
    "\n",
    "review_df_clean['review_score'] = review_df_clean['reviewer_score'].apply(lambda x: x.split(':')[0].strip() if pd.notnull(x) else x).astype(int)\n",
    "review_df_clean.drop(columns=['reviewer_score'], inplace=True)\n",
    "\n",
    "review_df_clean['review_correctness'] = review_df_clean['reviewer_correctness'].apply(lambda x: x.split(':')[0].strip() if pd.notnull(x) else x).astype(int)\n",
    "review_df_clean.drop(columns=['reviewer_correctness'], inplace=True)\n",
    "\n",
    "review_df_clean['review_technical_novelty_and_significance'] = review_df_clean['reviewer_technical_novelty_and_significance'].apply(lambda x: x.split(':')[0].strip() if pd.notnull(x) else x).astype(int)\n",
    "review_df_clean.drop(columns=['reviewer_technical_novelty_and_significance'], inplace=True)\n",
    "\n",
    "review_df_clean['review_empirical_novelty_and_significance'] = review_df_clean['reviewer_empirical_novelty_and_significance'].apply(lambda x: x.split(':')[0].strip() if pd.notnull(x) else x).astype(int)\n",
    "review_df_clean.drop(columns=['reviewer_empirical_novelty_and_significance'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Make all decisions have only \"Accept\"\n",
    "7. Add high_variance information by joining on paper_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_df_clean['decision'] = review_df_clean['decision'].apply(lambda x: \"Accept\" if \"accept\" in x.lower() else \"Reject\")\n",
    "review_df_clean = pd.merge(review_df_clean, df[['paper_id', 'is_high_variance']], on='paper_id', how='right')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reviewer Dataset is completed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataframe 2: Papers as rows and reviewer statistics per paper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use aggregation functions to calculate statistics per paper.\n",
    "- If you want to add a statistic or change one, add it to the lists next to the column names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "paper_df = review_df_clean.groupby('paper_id').agg({'time_to_deadline': ['std', 'mean'], \n",
    "                                                    'review_confidence': ['std', 'mean'],\n",
    "                                                    'review_score': ['std', 'mean', 'max', 'min'],\n",
    "                                                    'review_correctness': ['std', 'mean'],\n",
    "                                                    'review_technical_novelty_and_significance': ['std', 'mean'],\n",
    "                                                    'review_empirical_novelty_and_significance': ['std', 'mean'],\n",
    "                                                    'reviewer': 'count',\n",
    "                                                    'decision': 'first'}).reset_index()\n",
    "\n",
    "paper_df[\"reviewer1_score\"] = df[\"reviewer1_score\"] \n",
    "paper_df[\"reviewer2_score\"] = df[\"reviewer2_score\"] \n",
    "paper_df[\"reviewer3_score\"] = df[\"reviewer3_score\"] \n",
    "paper_df[\"reviewer4_score\"] = df[\"reviewer4_score\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>paper_id</th>\n",
       "      <th colspan=\"2\" halign=\"left\">time_to_deadline</th>\n",
       "      <th colspan=\"2\" halign=\"left\">review_confidence</th>\n",
       "      <th colspan=\"4\" halign=\"left\">review_score</th>\n",
       "      <th colspan=\"2\" halign=\"left\">review_correctness</th>\n",
       "      <th colspan=\"2\" halign=\"left\">review_technical_novelty_and_significance</th>\n",
       "      <th colspan=\"2\" halign=\"left\">review_empirical_novelty_and_significance</th>\n",
       "      <th>reviewer</th>\n",
       "      <th>decision</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>max</th>\n",
       "      <th>min</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>count</th>\n",
       "      <th>first</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>5 days 19:16:10.689828726</td>\n",
       "      <td>9 days 14:20:49</td>\n",
       "      <td>0.577350</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.500000</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>2.250000</td>\n",
       "      <td>4</td>\n",
       "      <td>Accept: poster</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2 days 06:32:55.872867145</td>\n",
       "      <td>12 days 22:53:01.333333333</td>\n",
       "      <td>0.577350</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>2.516611</td>\n",
       "      <td>5.666667</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>1.154701</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.577350</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>3</td>\n",
       "      <td>Reject</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1 days 12:54:38.117582429</td>\n",
       "      <td>9 days 09:35:52.250000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>4.750000</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>4.250000</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>2.750000</td>\n",
       "      <td>0.816497</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.577350</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>4</td>\n",
       "      <td>Reject</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2 days 13:20:58.514324593</td>\n",
       "      <td>11 days 04:09:52.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>3.250000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>0.577350</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>0.577350</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>2.309401</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>Accept: notable-top-5%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>5 days 09:23:30.024963235</td>\n",
       "      <td>12 days 02:20:32.750000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>3.750000</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>3.750000</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>0.577350</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>4</td>\n",
       "      <td>Reject</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3791</th>\n",
       "      <td>3791</td>\n",
       "      <td>5 days 23:13:08.435799653</td>\n",
       "      <td>16 days 11:16:41.666666666</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.154701</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0.577350</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>0.577350</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>1.154701</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>3</td>\n",
       "      <td>Reject</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3792</th>\n",
       "      <td>3792</td>\n",
       "      <td>4 days 09:28:45.175281084</td>\n",
       "      <td>11 days 22:56:18.250000</td>\n",
       "      <td>0.816497</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.449490</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1.290994</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>2.750000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>4</td>\n",
       "      <td>Reject</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3793</th>\n",
       "      <td>3793</td>\n",
       "      <td>1 days 20:41:21.379731310</td>\n",
       "      <td>11 days 20:54:33.750000</td>\n",
       "      <td>0.577350</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.500000</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>0.577350</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>2.250000</td>\n",
       "      <td>1.414214</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>Accept: poster</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3794</th>\n",
       "      <td>3794</td>\n",
       "      <td>3 days 09:33:53.422118322</td>\n",
       "      <td>8 days 04:57:49.750000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>3.750000</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>0.816497</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.577350</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>0.577350</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>4</td>\n",
       "      <td>Reject</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3795</th>\n",
       "      <td>3795</td>\n",
       "      <td>7 days 04:45:12.891550738</td>\n",
       "      <td>11 days 06:42:36</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.577350</td>\n",
       "      <td>5.666667</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>0.577350</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>0.577350</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>0.577350</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>3</td>\n",
       "      <td>Reject</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3796 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     paper_id          time_to_deadline                             \\\n",
       "                                    std                       mean   \n",
       "0           0 5 days 19:16:10.689828726            9 days 14:20:49   \n",
       "1           1 2 days 06:32:55.872867145 12 days 22:53:01.333333333   \n",
       "2           2 1 days 12:54:38.117582429     9 days 09:35:52.250000   \n",
       "3           3 2 days 13:20:58.514324593    11 days 04:09:52.500000   \n",
       "4           4 5 days 09:23:30.024963235    12 days 02:20:32.750000   \n",
       "...       ...                       ...                        ...   \n",
       "3791     3791 5 days 23:13:08.435799653 16 days 11:16:41.666666666   \n",
       "3792     3792 4 days 09:28:45.175281084    11 days 22:56:18.250000   \n",
       "3793     3793 1 days 20:41:21.379731310    11 days 20:54:33.750000   \n",
       "3794     3794 3 days 09:33:53.422118322     8 days 04:57:49.750000   \n",
       "3795     3795 7 days 04:45:12.891550738           11 days 06:42:36   \n",
       "\n",
       "     review_confidence           review_score                    \\\n",
       "                   std      mean          std      mean max min   \n",
       "0             0.577350  3.500000     1.000000  6.500000   8   6   \n",
       "1             0.577350  3.666667     2.516611  5.666667   8   3   \n",
       "2             0.500000  4.750000     1.500000  4.250000   6   3   \n",
       "3             0.500000  3.250000     0.000000  8.000000   8   8   \n",
       "4             0.500000  3.750000     1.500000  3.750000   6   3   \n",
       "...                ...       ...          ...       ...  ..  ..   \n",
       "3791          0.000000  4.000000     1.154701  3.666667   5   3   \n",
       "3792          0.816497  3.000000     2.449490  4.000000   6   1   \n",
       "3793          0.577350  3.500000     1.000000  6.500000   8   6   \n",
       "3794          0.000000  4.000000     1.500000  3.750000   6   3   \n",
       "3795          0.000000  4.000000     0.577350  5.666667   6   5   \n",
       "\n",
       "     review_correctness           review_technical_novelty_and_significance  \\\n",
       "                    std      mean                                       std   \n",
       "0              1.000000  3.500000                                  0.000000   \n",
       "1              1.154701  3.333333                                  1.000000   \n",
       "2              0.500000  2.750000                                  0.816497   \n",
       "3              0.577350  3.500000                                  0.577350   \n",
       "4              0.577350  3.500000                                  0.000000   \n",
       "...                 ...       ...                                       ...   \n",
       "3791           0.577350  3.333333                                  0.577350   \n",
       "3792           1.290994  2.500000                                  0.500000   \n",
       "3793           0.577350  3.500000                                  0.500000   \n",
       "3794           0.816497  3.000000                                  0.577350   \n",
       "3795           0.577350  2.666667                                  0.577350   \n",
       "\n",
       "               review_empirical_novelty_and_significance           reviewer  \\\n",
       "          mean                                       std      mean    count   \n",
       "0     3.000000                                  0.500000  2.250000        4   \n",
       "1     3.000000                                  0.577350  2.333333        3   \n",
       "2     2.000000                                  0.577350  1.500000        4   \n",
       "3     3.500000                                  2.309401  2.000000        4   \n",
       "4     2.000000                                  1.000000  1.500000        4   \n",
       "...        ...                                       ...       ...      ...   \n",
       "3791  2.666667                                  1.154701  0.666667        3   \n",
       "3792  2.750000                                  1.000000  0.500000        4   \n",
       "3793  2.250000                                  1.414214  2.000000        4   \n",
       "3794  2.500000                                  0.577350  2.500000        4   \n",
       "3795  2.666667                                  0.577350  2.666667        3   \n",
       "\n",
       "                    decision  \n",
       "                       first  \n",
       "0             Accept: poster  \n",
       "1                     Reject  \n",
       "2                     Reject  \n",
       "3     Accept: notable-top-5%  \n",
       "4                     Reject  \n",
       "...                      ...  \n",
       "3791                  Reject  \n",
       "3792                  Reject  \n",
       "3793          Accept: poster  \n",
       "3794                  Reject  \n",
       "3795                  Reject  \n",
       "\n",
       "[3796 rows x 17 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "paper_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add max-min difference column. This is our most basic metric for measuring discrepancy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "paper_df['review_score', 'max_min_diff'] = paper_df['review_score', 'max'] - paper_df['review_score', 'min']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add high discrepancy papers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "paper_df['is_high_discrepancy'] = (paper_df['review_score', 'max_min_diff'] >= 4).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paper Dataset is completed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  paper_id          time_to_deadline                             \\\n",
      "                                 std                       mean   \n",
      "0        0 5 days 19:16:10.689828726            9 days 14:20:49   \n",
      "1        1 2 days 06:32:55.872867145 12 days 22:53:01.333333333   \n",
      "2        2 1 days 12:54:38.117582429     9 days 09:35:52.250000   \n",
      "3        3 2 days 13:20:58.514324593    11 days 04:09:52.500000   \n",
      "4        4 5 days 09:23:30.024963235    12 days 02:20:32.750000   \n",
      "\n",
      "  review_confidence           review_score                    \\\n",
      "                std      mean          std      mean max min   \n",
      "0           0.57735  3.500000     1.000000  6.500000   8   6   \n",
      "1           0.57735  3.666667     2.516611  5.666667   8   3   \n",
      "2           0.50000  4.750000     1.500000  4.250000   6   3   \n",
      "3           0.50000  3.250000     0.000000  8.000000   8   8   \n",
      "4           0.50000  3.750000     1.500000  3.750000   6   3   \n",
      "\n",
      "  review_correctness           review_technical_novelty_and_significance       \\\n",
      "                 std      mean                                       std mean   \n",
      "0           1.000000  3.500000                                  0.000000  3.0   \n",
      "1           1.154701  3.333333                                  1.000000  3.0   \n",
      "2           0.500000  2.750000                                  0.816497  2.0   \n",
      "3           0.577350  3.500000                                  0.577350  3.5   \n",
      "4           0.577350  3.500000                                  0.000000  2.0   \n",
      "\n",
      "  review_empirical_novelty_and_significance           reviewer  \\\n",
      "                                        std      mean    count   \n",
      "0                                  0.500000  2.250000        4   \n",
      "1                                  0.577350  2.333333        3   \n",
      "2                                  0.577350  1.500000        4   \n",
      "3                                  2.309401  2.000000        4   \n",
      "4                                  1.000000  1.500000        4   \n",
      "\n",
      "                 decision review_score is_high_discrepancy  \n",
      "                    first max_min_diff                      \n",
      "0          Accept: poster            2                   0  \n",
      "1                  Reject            5                   1  \n",
      "2                  Reject            3                   0  \n",
      "3  Accept: notable-top-5%            0                   0  \n",
      "4                  Reject            3                   0  \n",
      "See the portion of papers accepted and rejected and has high discrepancy.\n",
      "(decision, first)\n",
      "Accept: notable-top-25%    0.100000\n",
      "Accept: notable-top-5%     0.098901\n",
      "Accept: poster             0.133111\n",
      "Reject                     0.182636\n",
      "Name: is_high_discrepancy, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(paper_df.head())\n",
    "\n",
    "print(\"See the portion of papers accepted and rejected and has high discrepancy.\")\n",
    "print(paper_df.groupby(('decision', 'first'))['is_high_discrepancy'].mean())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "brain-align",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
